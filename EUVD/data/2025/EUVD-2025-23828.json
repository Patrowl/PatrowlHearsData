{"id": "EUVD-2025-23828", "enisaUuid": "22690b7b-8cf2-32bf-b1a0-8e3290e13289", "description": "NVIDIA Triton Inference Server for Windows and Linux and the Tensor RT backend contain a vulnerability where an attacker could cause an underflow by a specific model configuration and a specific input. A successful exploit of this vulnerability might lead to denial of service.", "datePublished": "2025-08-06T12:44:08", "dateUpdated": "2025-08-06T13:27:04", "baseScore": 4.4, "baseScoreVersion": "3.1", "baseScoreVector": "CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:N/I:N/A:H", "references": ["https://nvd.nist.gov/vuln/detail/CVE-2025-23335", "https://www.cve.org/CVERecord?id=CVE-2025-23335", "https://nvidia.custhelp.com/app/answers/detail/a_id/5687"], "aliases": ["CVE-2025-23335"], "assigner": "nvidia", "epss": 0.05, "enisaIdProduct": [{"id": "a6a475ba-dd98-3822-a563-ae378adf056f", "product": {"name": "Triton Inference Server"}, "product_version": "All versions prior to 25.05"}], "enisaIdVendor": [{"id": "0ebfe64c-ea4a-3860-9c8d-152f4593ae60", "vendor": {"name": "NVIDIA"}}], "isExploited": false}