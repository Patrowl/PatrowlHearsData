{"id": "EUVD-2024-39637", "enisaUuid": "f3ded25f-34d1-389b-b88e-4b575e7e6f0b", "description": "llama.cpp provides LLM inference in C/C++. The unsafe `type` member in the `rpc_tensor` structure can cause `global-buffer-overflow`. This vulnerability may lead to memory data leakage. The vulnerability is fixed in b3561.", "datePublished": "2024-08-12T15:02:40", "dateUpdated": "2024-08-13T14:07:30", "baseScore": 5.3, "baseScoreVersion": "3.1", "baseScoreVector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N", "references": ["https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-mqp6-7pv6-fqjf", "https://github.com/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b"], "aliases": ["CVE-2024-42477"], "assigner": "GitHub_M", "epss": 0.2, "enisaIdProduct": [{"id": "99f9de4c-bd64-3bce-8957-3c65a3bce128", "product": {"name": "llama.cpp"}, "product_version": "< b3561"}], "enisaIdVendor": [{"id": "14fb89fe-2178-38b2-9332-1f344897055b", "vendor": {"name": "ggerganov"}}], "isExploited": false}