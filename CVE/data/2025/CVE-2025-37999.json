{"publishedDate": "2025-05-29T14:15Z", "lastModifiedDate": "2025-05-29T14:29Z", "cve": {"data_type": "CVE", "data_format": "MITRE", "data_version": "1.0", "CVE_data_meta": {"ID": "CVE-2025-37999", "ASSIGNER": "416baaa9-dc9f-4396-8d5f-8c081fb06d67"}, "description": {"description_data": [{"lang": "en", "value": "In the Linux kernel, the following vulnerability has been resolved:\n\nfs/erofs/fileio: call erofs_onlinefolio_split() after bio_add_folio()\n\nIf bio_add_folio() fails (because it is full),\nerofs_fileio_scan_folio() needs to submit the I/O request via\nerofs_fileio_rq_submit() and allocate a new I/O request with an empty\n`struct bio`.  Then it retries the bio_add_folio() call.\n\nHowever, at this point, erofs_onlinefolio_split() has already been\ncalled which increments `folio->private`; the retry will call\nerofs_onlinefolio_split() again, but there will never be a matching\nerofs_onlinefolio_end() call.  This leaves the folio locked forever\nand all waiters will be stuck in folio_wait_bit_common().\n\nThis bug has been added by commit ce63cb62d794 (\"erofs: support\nunencoded inodes for fileio\"), but was practically unreachable because\nthere was room for 256 folios in the `struct bio` - until commit\n9f74ae8c9ac9 (\"erofs: shorten bvecs[] for file-backed mounts\") which\nreduced the array capacity to 16 folios.\n\nIt was now trivial to trigger the bug by manually invoking readahead\nfrom userspace, e.g.:\n\n posix_fadvise(fd, 0, st.st_size, POSIX_FADV_WILLNEED);\n\nThis should be fixed by invoking erofs_onlinefolio_split() only after\nbio_add_folio() has succeeded.  This is safe: asynchronous completions\ninvoking erofs_onlinefolio_end() will not unlock the folio because\nerofs_fileio_scan_folio() is still holding a reference to be released\nby erofs_onlinefolio_end() at the end."}, {"lang": "es", "value": "En el kernel de Linux, se ha resuelto la siguiente vulnerabilidad: fs/erofs/fileio: llamar a erofs_onlinefolio_split() despu\u00e9s de bio_add_folio(). Si bio_add_folio() falla (porque est\u00e1 lleno), erofs_fileio_scan_folio() debe enviar la solicitud de E/S mediante erofs_fileio_rq_submit() y asignar una nueva solicitud de E/S con un `struct bio` vac\u00edo. Luego, vuelve a intentar la llamada a bio_add_folio(). Sin embargo, en este punto, ya se ha llamado a erofs_onlinefolio_split(), lo que incrementa `folio-&gt;private`; el reintento llamar\u00e1 a erofs_onlinefolio_split() de nuevo, pero nunca habr\u00e1 una llamada erofs_onlinefolio_end() coincidente. Esto deja el folio bloqueado para siempre y todos los que esperan quedar\u00e1n atascados en folio_wait_bit_common(). Este error se a\u00f1adi\u00f3 con el commit ce63cb62d794 (\"erofs: compatibilidad con inodos no codificados para fileio\"), pero era pr\u00e1cticamente imposible de solucionar porque hab\u00eda espacio para 256 folios en la estructura `struct bio`, hasta el commit 9f74ae8c9ac9 (\"erofs: acortar bvecs[] para montajes con respaldo de archivo\"), que redujo la capacidad del array a 16 folios. Ahora era f\u00e1cil activar el error invocando manualmente la lectura anticipada desde el espacio de usuario, por ejemplo: posix_fadvise(fd, 0, st.st_size, POSIX_FADV_WILLNEED); Esto deber\u00eda solucionarse invocando erofs_onlinefolio_split() solo despu\u00e9s de que bio_add_folio() se haya ejecutado correctamente. Esto es seguro: las finalizaciones asincr\u00f3nicas que invocan erofs_onlinefolio_end() no desbloquear\u00e1n el folio porque erofs_fileio_scan_folio() todav\u00eda contiene una referencia que erofs_onlinefolio_end() liberar\u00e1 al final."}]}, "references": {"reference_data": [{"url": "https://git.kernel.org/stable/c/61e0fc3312309867e5a3495329dad0286d2a5703", "name": "", "refsource": "", "tags": []}, {"url": "https://git.kernel.org/stable/c/bbfe756dc3062c1e934f06e5ba39c239aa953b92", "name": "", "refsource": "", "tags": []}, {"url": "https://git.kernel.org/stable/c/c26076197df348c84cc23e5962d61902e072a0f5", "name": "", "refsource": "", "tags": []}]}, "problemtype": {"problemtype_data": [{"description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}]}}, "impact": {}, "configurations": {"CVE_data_version": "4.0", "nodes": []}}