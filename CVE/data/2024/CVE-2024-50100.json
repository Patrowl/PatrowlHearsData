{"publishedDate": "2024-11-05T18:15Z", "lastModifiedDate": "2025-10-01T21:15Z", "cve": {"data_type": "CVE", "data_format": "MITRE", "data_version": "1.0", "CVE_data_meta": {"ID": "CVE-2024-50100", "ASSIGNER": "416baaa9-dc9f-4396-8d5f-8c081fb06d67"}, "description": {"description_data": [{"lang": "en", "value": "In the Linux kernel, the following vulnerability has been resolved:\n\nUSB: gadget: dummy-hcd: Fix \"task hung\" problem\n\nThe syzbot fuzzer has been encountering \"task hung\" problems ever\nsince the dummy-hcd driver was changed to use hrtimers instead of\nregular timers.  It turns out that the problems are caused by a subtle\ndifference between the timer_pending() and hrtimer_active() APIs.\n\nThe changeover blindly replaced the first by the second.  However,\ntimer_pending() returns True when the timer is queued but not when its\ncallback is running, whereas hrtimer_active() returns True when the\nhrtimer is queued _or_ its callback is running.  This difference\noccasionally caused dummy_urb_enqueue() to think that the callback\nroutine had not yet started when in fact it was almost finished.  As a\nresult the hrtimer was not restarted, which made it impossible for the\ndriver to dequeue later the URB that was just enqueued.  This caused\nusb_kill_urb() to hang, and things got worse from there.\n\nSince hrtimers have no API for telling when they are queued and the\ncallback isn't running, the driver must keep track of this for itself.\nThat's what this patch does, adding a new \"timer_pending\" flag and\nsetting or clearing it at the appropriate times."}, {"lang": "es", "value": "En el kernel de Linux, se ha resuelto la siguiente vulnerabilidad: USB: gadget: dummy-hcd: soluciona el problema de \"tarea colgada\" El fuzzer syzbot ha estado encontrando problemas de \"tarea colgada\" desde que se cambi\u00f3 el controlador dummy-hcd para usar temporizadores hrtimer en lugar de temporizadores normales. Resulta que los problemas son causados por una diferencia sutil entre las API timer_pending() y hrtimer_active(). El cambio reemplaz\u00f3 ciegamente la primera por la segunda. Sin embargo, timer_pending() devuelve True cuando el temporizador est\u00e1 en cola pero no cuando su devoluci\u00f3n de llamada se est\u00e1 ejecutando, mientras que hrtimer_active() devuelve True cuando el hrtimer est\u00e1 en cola _o_ su devoluci\u00f3n de llamada se est\u00e1 ejecutando. Esta diferencia ocasionalmente hizo que dummy_urb_enqueue() pensara que la rutina de devoluci\u00f3n de llamada a\u00fan no hab\u00eda comenzado cuando, de hecho, estaba casi terminada. Como resultado, el hrtimer no se reinici\u00f3, lo que hizo imposible que el controlador quitara de la cola m\u00e1s tarde el URB que acababa de ponerse en cola. Esto provoc\u00f3 que usb_kill_urb() se bloqueara y las cosas empeoraron a partir de ah\u00ed. Dado que los temporizadores hr no tienen una API para saber cu\u00e1ndo est\u00e1n en cola y la devoluci\u00f3n de llamada no se est\u00e1 ejecutando, el controlador debe realizar un seguimiento de esto por s\u00ed mismo. Eso es lo que hace este parche, agregando un nuevo indicador \"timer_pending\" y configur\u00e1ndolo o borr\u00e1ndolo en los momentos apropiados."}]}, "references": {"reference_data": [{"url": "https://git.kernel.org/stable/c/5189df7b8088268012882c220d6aca4e64981348", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/7d85884576a3be3616c260fc1fa862a59579d1ab", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/cf7ee2291da551fc4b109fda1f6a332cb8212065", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/f828205ee3e4ddc712a13fba6c9902d51e91ddaf", "name": "", "refsource": "", "tags": ["Patch"]}]}, "problemtype": {"problemtype_data": [{"description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}]}}, "impact": {"baseMetricV3": {"exploitabilityScore": 1.8, "impactScore": 3.6, "cvssV3": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "baseScore": 5.5, "baseSeverity": "MEDIUM", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH"}}}, "configurations": {"CVE_data_version": "4.0", "nodes": [{"operator": "OR", "negate": false, "children": [], "cpe_match": [{"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "E1D573E2-61FD-4C3B-B3BD-5FBEFD6391F0", "cpe_name": [], "versionStartIncluding": "6.10", "versionEndExcluding": "6.11.5"}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:6.12:rc1:*:*:*:*:*:*", "matchCriteriaId": "7F361E1D-580F-4A2D-A509-7615F73167A1", "cpe_name": []}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:6.12:rc2:*:*:*:*:*:*", "matchCriteriaId": "925478D0-3E3D-4E6F-ACD5-09F28D5DF82C", "cpe_name": []}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:6.12:rc3:*:*:*:*:*:*", "matchCriteriaId": "3C95E234-D335-4B6C-96BF-E2CEBD8654ED", "cpe_name": []}]}]}}