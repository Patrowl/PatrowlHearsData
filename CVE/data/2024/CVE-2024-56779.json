{"publishedDate": "2025-01-08T18:15Z", "lastModifiedDate": "2025-10-01T20:17Z", "cve": {"data_type": "CVE", "data_format": "MITRE", "data_version": "1.0", "CVE_data_meta": {"ID": "CVE-2024-56779", "ASSIGNER": "416baaa9-dc9f-4396-8d5f-8c081fb06d67"}, "description": {"description_data": [{"lang": "en", "value": "In the Linux kernel, the following vulnerability has been resolved:\n\nnfsd: fix nfs4_openowner leak when concurrent nfsd4_open occur\n\nThe action force umount(umount -f) will attempt to kill all rpc_task even\numount operation may ultimately fail if some files remain open.\nConsequently, if an action attempts to open a file, it can potentially\nsend two rpc_task to nfs server.\n\n                   NFS CLIENT\nthread1                             thread2\nopen(\"file\")\n...\nnfs4_do_open\n _nfs4_do_open\n  _nfs4_open_and_get_state\n   _nfs4_proc_open\n    nfs4_run_open_task\n     /* rpc_task1 */\n     rpc_run_task\n     rpc_wait_for_completion_task\n\n                                    umount -f\n                                    nfs_umount_begin\n                                     rpc_killall_tasks\n                                      rpc_signal_task\n     rpc_task1 been wakeup\n     and return -512\n _nfs4_do_open // while loop\n    ...\n    nfs4_run_open_task\n     /* rpc_task2 */\n     rpc_run_task\n     rpc_wait_for_completion_task\n\nWhile processing an open request, nfsd will first attempt to find or\nallocate an nfs4_openowner. If it finds an nfs4_openowner that is not\nmarked as NFS4_OO_CONFIRMED, this nfs4_openowner will released. Since\ntwo rpc_task can attempt to open the same file simultaneously from the\nclient to server, and because two instances of nfsd can run\nconcurrently, this situation can lead to lots of memory leak.\nAdditionally, when we echo 0 to /proc/fs/nfsd/threads, warning will be\ntriggered.\n\n                    NFS SERVER\nnfsd1                  nfsd2       echo 0 > /proc/fs/nfsd/threads\n\nnfsd4_open\n nfsd4_process_open1\n  find_or_alloc_open_stateowner\n   // alloc oo1, stateid1\n                       nfsd4_open\n                        nfsd4_process_open1\n                        find_or_alloc_open_stateowner\n                        // find oo1, without NFS4_OO_CONFIRMED\n                         release_openowner\n                          unhash_openowner_locked\n                          list_del_init(&oo->oo_perclient)\n                          // cannot find this oo\n                          // from client, LEAK!!!\n                         alloc_stateowner // alloc oo2\n\n nfsd4_process_open2\n  init_open_stateid\n  // associate oo1\n  // with stateid1, stateid1 LEAK!!!\n  nfs4_get_vfs_file\n  // alloc nfsd_file1 and nfsd_file_mark1\n  // all LEAK!!!\n\n                         nfsd4_process_open2\n                         ...\n\n                                    write_threads\n                                     ...\n                                     nfsd_destroy_serv\n                                      nfsd_shutdown_net\n                                       nfs4_state_shutdown_net\n                                        nfs4_state_destroy_net\n                                         destroy_client\n                                          __destroy_client\n                                          // won't find oo1!!!\n                                     nfsd_shutdown_generic\n                                      nfsd_file_cache_shutdown\n                                       kmem_cache_destroy\n                                       for nfsd_file_slab\n                                       and nfsd_file_mark_slab\n                                       // bark since nfsd_file1\n                                       // and nfsd_file_mark1\n                                       // still alive\n\n=======================================================================\nBUG nfsd_file (Not tainted): Objects remaining in nfsd_file on\n__kmem_cache_shutdown()\n-----------------------------------------------------------------------\n\nSlab 0xffd4000004438a80 objects=34 used=1 fp=0xff11000110e2ad28\nflags=0x17ffffc0000240(workingset|head|node=0|zone=2|lastcpupid=0x1fffff)\nCPU: 4 UID: 0 PID: 757 Comm: sh Not tainted 6.12.0-rc6+ #19\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS\n1.16.1-2.fc37 04/01/2014\nCall Trace:\n <TASK>\n dum\n---truncated---"}, {"lang": "es", "value": "En el kernel de Linux, se ha resuelto la siguiente vulnerabilidad: nfsd: se corrige la p\u00e9rdida de nfs4_openowner cuando se producen nfsd4_open concurrentes. La acci\u00f3n force umount(umount -f) intentar\u00e1 eliminar todas las rpc_task, aunque la operaci\u00f3n umount puede fallar si algunos archivos permanecen abiertos. En consecuencia, si una acci\u00f3n intenta abrir un archivo, puede enviar dos rpc_task al servidor nfs. CLIENTE NFS thread1 thread2 open(\"archivo\") ... nfs4_do_open _nfs4_do_open _nfs4_open_and_get_state _nfs4_proc_open nfs4_run_open_task /* rpc_task1 */ rpc_run_task rpc_wait_for_completion_task umount -f nfs_umount_begin rpc_killall_tasks rpc_signal_task rpc_task1 se ha activado y ha devuelto -512 _nfs4_do_open // bucle while ... nfs4_run_open_task /* rpc_task2 */ rpc_run_task rpc_wait_for_completion_task Mientras se procesa una solicitud de apertura, nfsd primero intentar\u00e1 encontrar o asignar un nfs4_openowner. Si encuentra un nfs4_openowner que no est\u00e9 marcado como NFS4_OO_CONFIRMED, este nfs4_openowner se liberar\u00e1. Dado que dos rpc_task pueden intentar abrir el mismo archivo simult\u00e1neamente desde el cliente al servidor, y debido a que dos instancias de nfsd pueden ejecutarse simult\u00e1neamente, esta situaci\u00f3n puede provocar una gran p\u00e9rdida de memoria. Adem\u00e1s, cuando hacemos eco de 0 en /proc/fs/nfsd/threads, se activar\u00e1 una advertencia. SERVIDOR NFS nfsd1 nfsd2 echo 0 &gt; /proc/fs/nfsd/threads nfsd4_open nfsd4_process_open1 find_or_alloc_open_stateowner // asignar oo1, stateid1 nfsd4_open nfsd4_process_open1 find_or_alloc_open_stateowner // encontrar oo1, sin NFS4_OO_CONFIRMED release_openowner unhash_openowner_locked list_del_init(&amp;oo-&gt;oo_perclient) // no se puede encontrar este oo // del cliente, \u00a1FUGA! alloc_stateowner // asignar oo2 nfsd4_process_open2 init_open_stateid // asociar oo1 // con stateid1, stateid1 \u00a1FUGA! nfs4_get_vfs_file // asignar nfsd_file1 y nfsd_file_mark1 // \u00a1\u00a1\u00a1TODOS FUGAN!!! nfsd4_process_open2 ... subprocesos de escritura ... nfsd_destroy_serv nfsd_shutdown_net nfs4_state_shutdown_net nfs4_state_destroy_net destroy_client __destroy_client // \u00a1\u00a1\u00a1No encontrar\u00e1 oo1!!! nfsd_shutdown_generic nfsd_file_cache_shutdown kmem_cache_destroy para nfsd_file_slab y nfsd_file_mark_slab // sin cambios desde nfsd_file1 // y nfsd_file_mark1 // siguen activos ============================================================================ ERROR nfsd_file (no contaminado): objetos que permanecen en nfsd_file en __kmem_cache_shutdown() ----------------------------------------------------------------------- Slab 0xffd4000004438a80 objetos=34 usados=1 fp=0xff11000110e2ad28 flags=0x17ffffc0000240(workingset|head|node=0|zone=2|lastcpupid=0x1fffff) CPU: 4 UID: 0 PID: 757 Comm: sh No contaminado 6.12.0-rc6+ #19 Nombre del hardware: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.16.1-2.fc37 01/04/2014 Seguimiento de llamadas:  dum ---truncado---"}]}, "references": {"reference_data": [{"url": "https://git.kernel.org/stable/c/0ab0a3ad24e970e894abcac58f85c332d1726749", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/2d505a801e57428057563762f67a5a62009b2600", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/37dfc81266d3a32294524bfadd3396614f8633ee", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/45abb68c941ebc9a35c6d3a7b08196712093c636", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/6f73f920b7ad0084373e46121d7ac34117aed652", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/98100e88dd8865999dc6379a3356cd799795fe7b", "name": "", "refsource": "", "tags": ["Patch"]}, {"url": "https://git.kernel.org/stable/c/a85364f0d30dee01c5d5b4afa55a9629a8f36d8e", "name": "", "refsource": "", "tags": ["Patch"]}]}, "problemtype": {"problemtype_data": [{"description": [{"lang": "en", "value": "CWE-401"}]}]}}, "impact": {"baseMetricV3": {"exploitabilityScore": 1.8, "impactScore": 3.6, "cvssV3": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "baseScore": 5.5, "baseSeverity": "MEDIUM", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH"}}}, "configurations": {"CVE_data_version": "4.0", "nodes": [{"operator": "OR", "negate": false, "children": [], "cpe_match": [{"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "DC7D5C80-B677-4131-A399-3366D7F3961C", "cpe_name": [], "versionEndExcluding": "5.4.287"}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "B5C644CC-2BD7-4E32-BC54-8DCC7ABE9935", "cpe_name": [], "versionStartIncluding": "5.5", "versionEndExcluding": "5.10.231"}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "419FD073-1517-4FD5-8158-F94BC68A1E89", "cpe_name": [], "versionStartIncluding": "5.11", "versionEndExcluding": "5.15.174"}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "09AC6122-E2A4-40FE-9D33-268A1B2EC265", "cpe_name": [], "versionStartIncluding": "5.16", "versionEndExcluding": "6.1.120"}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "CA16DEE3-ABEC-4449-9F4A-7A3DC4FC36C7", "cpe_name": [], "versionStartIncluding": "6.2", "versionEndExcluding": "6.6.64"}, {"vulnerable": true, "cpe23Uri": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "matchCriteriaId": "04756810-D093-4B43-B1D9-CF5035968061", "cpe_name": [], "versionStartIncluding": "6.7", "versionEndExcluding": "6.12.4"}]}]}}