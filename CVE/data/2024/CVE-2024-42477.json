{"cve": {"data_type": "CVE", "data_format": "MITRE", "data_version": "4.0", "CVE_data_meta": {"ID": "CVE-2024-42477", "ASSIGNER": "security-advisories@github.com"}, "problemtype": {"problemtype_data": [{"description": []}]}, "references": {"reference_data": [{"url": "https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-mqp6-7pv6-fqjf", "name": "https://github.com/ggerganov/llama.cpp/security/advisories/GHSA-mqp6-7pv6-fqjf", "refsource": "", "tags": []}, {"url": "https://github.com/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b", "name": "https://github.com/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b", "refsource": "", "tags": []}]}, "description": {"description_data": [{"lang": "en", "value": "llama.cpp provides LLM inference in C/C++. The unsafe `type` member in the `rpc_tensor` structure can cause `global-buffer-overflow`. This vulnerability may lead to memory data leakage. The vulnerability is fixed in b3561."}]}}, "configurations": {"CVE_data_version": "4.0", "nodes": []}, "impact": {}, "publishedDate": "2024-08-12T15:15Z", "lastModifiedDate": "2024-08-12T18:57Z"}